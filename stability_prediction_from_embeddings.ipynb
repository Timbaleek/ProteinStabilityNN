{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Protein stability prediction\n",
    "\n",
    "In the project you will try to predict protein stability changes upon point mutations. \n",
    "We will use acuumulated data from experimental databases, i.e. the Megascale dataset. A current [pre-print paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10402116/) has already preprocessed the dataset and created homology reduced data splits. We will reuse these. To do so, download the data folder from [here](https://polybox.ethz.ch/index.php/s/txvcb5jKy1A0TbY) and unzip it.  \n",
    "\n",
    "The data includes measurements of changes in the Gibbs free enrgy ($\\Delta \\Delta G $). \n",
    "This will be the value that you will have to predict for a given protein with a point mutation. \n",
    "As input data you can use the protein sequence or a protein embedding retreived from ESM, a state of the art protein model.  \n",
    "\n",
    "Here we will use protein embeddings computed by ESM as input. \n",
    "We provide precomputed embeddings from the last layer of the smallest ESM model. You can adjust the Dataloader's code to load the embedding of the wild type or of the mutaed sequence or both. You can use it however you like. This is just to provide you easy access to embeddings. If you want to compute your own embeddings from other layers or models you can do that, too. \n",
    "\n",
    "Below we provide you with a strcuture for the project that you can start with.  \n",
    "Edit the cells to your liking and add more code to create your final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import lightning as L\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.regression import PearsonCorrCoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloading\n",
    "\n",
    "We are using the Megascale dataset. The train, validation and test sets are already predefined.  \n",
    "As mentioned, we provide embeddings from the last layer of ESM as input. You can access either the wild type or the mutated sequence and you could also further adjsut the embeddings. \n",
    "Here we have an embedding representing the complete sequence. It was computed by averaging over the embeddings per residue in the sequence. \n",
    "\n",
    "The ``Dataset`` classes return tuples of ``(embedding, ddg_value)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataloaders load the tensors from memory one by one, could potentially become a bottleneck\n",
    "\n",
    "class ProtEmbeddingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for the embeddings of the mutated sequences\n",
    "    You can the get_item() method to return the data in the format you want\n",
    "    \"\"\"\n",
    "    def __init__(self, tensor_folder, csv_file, id_col=\"name\", label_col=\"ddG_ML\"):\n",
    "        \"\"\"\n",
    "        Initialize the dataset\n",
    "        input at init: \n",
    "            tensor_folder: path to the directory with the embeddings we want to use, eg. \"/home/data/mega_train_embeddings\"\n",
    "            cvs_file: path to the csv file corresponding to the data, eg. \"home/data/mega_train.csv\"\n",
    "        \"\"\"\n",
    "        self.tensor_folder = tensor_folder\n",
    "        self.df = pd.read_csv(csv_file, sep=\",\")\n",
    "        # only use the mutation rows\n",
    "        self.df = self.df[self.df.mut_type!=\"wt\"]\n",
    "        # get the labels and ids\n",
    "        self.labels = torch.tensor(self.df[label_col].values)\n",
    "        self.ids = self.df[id_col].values\n",
    "        self.wt_names = self.df[\"WT_name\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load embeddings\n",
    "        # mutation embedding\n",
    "        tensor_path = os.path.join(self.tensor_folder, self.ids[idx] + \".pt\")\n",
    "        tensor = torch.load(tensor_path)['mean_representations'][6]\n",
    "\n",
    "        # wildtype embedding, uncomment if you want to use this, too\n",
    "        #tensor_path_wt = os.path.join(self.tensor_folder, self.wt_names[idx] + \".pt\")\n",
    "        #tensor_wt = torch.load(tensor_path_wt)['mean_representations'][6]\n",
    "\n",
    "        label = self.labels[idx] # ddG value\n",
    "        # returns a tuple of the input embedding and the target ddG values\n",
    "        return tensor, label.float()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/course/ProteinStabilityNN'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goOneUp()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#go one directory up\n",
    "def goOneUp():\n",
    "    path_parent = os.path.dirname(os.getcwd())\n",
    "\n",
    "    os.chdir(path_parent)\n",
    "    os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage \n",
    "# make sure to adjust the paths to where your files are located\n",
    "dataset_train = ProtEmbeddingDataset('project_data/project_data/mega_train_embeddings', 'project_data/project_data/mega_train.csv')\n",
    "dataset_val = ProtEmbeddingDataset('project_data/project_data/mega_val_embeddings', 'project_data/project_data/mega_val.csv')\n",
    "dataset_test = ProtEmbeddingDataset('project_data/project_data/mega_test_embeddings', 'project_data/project_data/mega_test.csv')\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=1024, shuffle=True, num_workers=16)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=512, shuffle=False, num_workers=16)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture and training\n",
    "\n",
    "Now it's your turn. Create a model trained on the embeddings and the corresponding ddG values.  \n",
    "Be aware that this is not a classification task, but a regression task. You want to predict a continuous number that is as close to the measured $\\Delta \\Delta G $ value as possible.\n",
    "You will need to adjust your architecture and loss accordingly.\n",
    "\n",
    "Train the model with the predefined dataloaders. And try to improve the model. \n",
    "Only test on the test set at the very end, when you have finished fine-tuning you model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ProtEmbeddingDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_test\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ProtEmbeddingDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_test.__getitem__(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the output shape of our data after a convolution and pooling of a certain size\n",
    "\n",
    "def get_conv2d_out_shape(tensor_shape, conv, pool=2):\n",
    "    # return the new shape of the tensor after a convolution and pooling\n",
    "    # tensor_shape: (channels, height, width)\n",
    "    # convolution arguments\n",
    "    kernel_size = conv.kernel_size\n",
    "    stride=conv.stride # 2D array\n",
    "    padding=conv.padding # 2D array\n",
    "    dilation=conv.dilation # 2D array\n",
    "    out_channels = conv.out_channels\n",
    "\n",
    "    height_out = np.floor((tensor_shape[1]+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
    "    #width_out = np.floor((tensor_shape[2]+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "    \n",
    "    if pool:\n",
    "        # adjust dimensions to pooling\n",
    "        height_out/=pool\n",
    "        #width_out/=pool\n",
    "        \n",
    "    return int(out_channels),int(height_out)#,int(width_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "class linModel(nn.Module):\n",
    "    \n",
    "    # Network Initialisation\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(embedConvModel, self).__init__() #initialize parent pytorch module\n",
    "\n",
    "        # read parameters\n",
    "        inputShape = params[\"inputShape\"]\n",
    "        kernelSize = params[\"kernelSize\"]\n",
    "        \n",
    "        #channels_out = params[\"initial_depth\"] \n",
    "        #fc1_size = params[\"fc1_size\"]\n",
    "        \n",
    "        #### Convolution Layers\n",
    "\n",
    "        # Max pooling layer\n",
    "        #self.pool = nn.MaxPool1d(2)\n",
    "        ##conv layer 1\n",
    "        # convolution with kernel size 8, goes from three channels to \n",
    "        # number defined by initial_depth in params\n",
    "        #self.conv1 = nn.Conv1d(inputShape[0], inputShape[0], kernel_size=kernelSize[0])#, padding=int((kernelSize[0]-1)/2), padding_mode='zeros')\n",
    "        #shape in = (3, 256, 256)\n",
    "        #print(inputShape)\n",
    "        #outShape = get_conv2d_out_shape(inputShape, self.conv1)#, pool=2)\n",
    "        #print(outShape)\n",
    "        #flatSize = outShape[1]# * outShape[2] #768 * 1024\n",
    "        #print(flatSize)\n",
    "        #self.fc = nn.Linear(flatSize, 1024)#outShape[1])\n",
    "\n",
    "    def forward(self,X):\n",
    "        # our network's forward pass\n",
    "        \n",
    "        # Convolution & Pool Layers\n",
    "        ############# TODO ###############\n",
    "        # convolution (conv1), then relu, then max pool \n",
    "        #print(X.shape)\n",
    "        X = F.tanh(self.conv1(X))\n",
    "        #print(X.shape)\n",
    "        #X = self.pool(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "       # print(X.shape)\n",
    "        \n",
    "        X = self.fc(X)\n",
    "        #print(X.shape)\n",
    "        #####################################\n",
    "        # return log softmax to fit classification problem, no relu needed\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code\n",
    "class embedConvModel(nn.Module):\n",
    "    \n",
    "    # Network Initialisation\n",
    "    def __init__(self, params):\n",
    "        \n",
    "        super(embedConvModel, self).__init__() #initialize parent pytorch module\n",
    "\n",
    "        # read parameters\n",
    "        inputShape = params[\"inputShape\"]\n",
    "        kernelSize = params[\"kernelSize\"]\n",
    "        \n",
    "        #channels_out = params[\"initial_depth\"] \n",
    "        #fc1_size = params[\"fc1_size\"]\n",
    "        \n",
    "        #### Convolution Layers\n",
    "\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool1d(5)\n",
    "        ##conv layer 1\n",
    "        # convolution with kernel size 8, goes from three channels to \n",
    "        # number defined by initial_depth in params\n",
    "        \n",
    "        \n",
    "        \n",
    "        outShape = (1, 1, 1)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(inputShape[0], outShape[0], kernel_size=kernelSize[0])#, padding=int((kernelSize[0]-1)/2), padding_mode='zeros')\n",
    "\n",
    "        \n",
    "        outShape = get_conv2d_out_shape(inputShape, self.conv1, pool=5)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv1d(outShape[0], outShape[0], kernel_size=kernelSize[1])#, padding=int((kernelSize[0]-1)/2), padding_mode='zeros')\n",
    "\n",
    "        outShape = get_conv2d_out_shape(outShape, self.conv2, pool=5)\n",
    "        #print(\"outShape\", outShape)\n",
    "        self.fc = nn.Linear(outShape[1], 1)#outShape[1])\n",
    "        \n",
    "    def forward(self,X):\n",
    "        # our network's forward pass\n",
    "        #print(\"before tanh\")\n",
    "        # Convolution & Pool Layers\n",
    "        ############# TODO ###############\n",
    "        # convolution (conv1), then relu, then max pool \n",
    "        X = F.leaky_relu(self.conv1(X))\n",
    "        X = self.pool(X)\n",
    "        X = F.sigmoid(self.conv2(X)) #all inputs converge to the same values because of sigmoid then pooling \n",
    "        X = self.pool(X)\n",
    "        #print(\"after tanh\")\n",
    "\n",
    "        #####################################\n",
    "        # return log softmax to fit classification problem, no relu needed\n",
    "        return self.fc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitMRIModel(L.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        ######## TODO ##########\n",
    "        # pass our model \n",
    "        self.model = model\n",
    "        #pass the learning rate\n",
    "        self.lr = learning_rate\n",
    "        # define loss function\n",
    "        self.loss_function = nn.MSELoss() #TODO\n",
    "        # define accuracy metric (torchmetrics)\n",
    "        #self.accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        ########################\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        ######### TODO #############\n",
    "        \n",
    "        # read from batch\n",
    "        # TODO\n",
    "        x,y = batch\n",
    "        x = torch.unsqueeze(x,1)\n",
    "        #print(x.shape)\n",
    "        #print(y)\n",
    "        # run data through model\n",
    "        predictions = self.model(x)#.squeeze(1)\n",
    "        #print(predictions.shape)\n",
    "       # print(y.shape)\n",
    "        #print(predictions.shape)\n",
    "        # compute loss\n",
    "        # 1 prediction\n",
    "        loss = self.loss_function(predictions, y)\n",
    "        #loss = self.loss_function(predictions, y)\n",
    "        # compute accuracy\n",
    "        #acc = self.accuracy(predictions, y)\n",
    "        ##############################\n",
    "\n",
    "        # logging the values (will appear in progress bar and on dashboard)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        #self.log(\"train_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        ############## TODO ################\n",
    "        # define the optimizer, let's use Adam\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        ####################################\n",
    "        return optimizer\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "\n",
    "        ############### TODO #############\n",
    "        # read from batch\n",
    "        x,y = batch\n",
    "\n",
    "        x = torch.unsqueeze(x,1)\n",
    "        # run data through model\n",
    "        predictions = self.model(x).squeeze(1)\n",
    "        \n",
    "        # compute loss\n",
    "        #loss = loss(prediction,labels[mask==1])\n",
    "        loss = self.loss_function(predictions, y)\n",
    "        # compute accuracy\n",
    "        #acc = self.accuracy(predictions, y)\n",
    "        ##############################\n",
    "\n",
    "        # logging\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        return loss#, acc\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        ############### TODO #############\n",
    "        # read from batch\n",
    "        x,y = batch\n",
    "\n",
    "        x = torch.unsqueeze(x,1)\n",
    "        #print(x.shape)\n",
    "        #print(x.shape)\n",
    "        #print(y.shape)\n",
    "        # run data through model\n",
    "        predictions = self.model(x).squeeze(1).squeeze(1)\n",
    "        #print(predictions.shape)\n",
    "        # compute loss\n",
    "        loss = self.loss_function(predictions, y)\n",
    "        #loss = self.loss_function(predictions, y)\n",
    "        # compute accuracy\n",
    "        #acc = self.accuracy(predictions, y)#torchmetrics.classification.Accuracy(task=\"MULTICLASS\", num_classes=2)\n",
    "        ##############################\n",
    "\n",
    "        # logging\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        #self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "params_model={\n",
    "    \"inputShape\": (1, batch[0].shape[1]),\n",
    "    \"kernelSize\": (7,11)\n",
    "    }\n",
    "\n",
    "# define computation hardware approach (GPU/CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Instantiate the model\n",
    "cnn_model = embedConvModel(params_model)\n",
    "# moves the model to GPU if available\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "#channel, batch, weight\n",
    "#inputShape (1, 1024, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.3381e-02, -1.3375e-04,  5.4088e-01,  ..., -7.0208e-01,\n",
       "        -6.7147e-01, -7.5817e-01])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(batch[0],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | model         | embedConvModel | 49    \n",
      "1 | loss_function | MSELoss        | 0     \n",
      "-------------------------------------------------\n",
      "49        Trainable params\n",
      "0         Non-trainable params\n",
      "49        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f24a563a7964a94b90c67e345baa605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                 | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "########## TODO #############\n",
    "# instantiate lightning model with the cnn_model and learning_rate=1e-3\n",
    "model = LitMRIModel(cnn_model, learning_rate=1e-3)\n",
    "############################\n",
    "\n",
    "# instantiate the lightning trainer \n",
    "trainer = L.Trainer(max_epochs=20, log_every_n_steps=1)#, callbacks=[FineTuneLearningRateFinder(milestones=(5, 10))])\n",
    "# train\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and visualization\n",
    "\n",
    "To get a good feeling of how the model is performing and to compare with literature, compute the Pearson and Spearman correlations.\n",
    "You can also plot the predictions in a scatterplot. We have added some code for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x142 and 1x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x,y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(x,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m cnn_model(x\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[1;32m      9\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(y_hat\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     10\u001b[0m all_y\u001b[38;5;241m.\u001b[39mappend(y\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[78], line 56\u001b[0m, in \u001b[0;36membedConvModel.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     49\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(X)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#        X = F.sigmoid(self.conv2(X))\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#        X = self.pool(X)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m#print(\"after tanh\")\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m#####################################\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;66;03m# return log softmax to fit classification problem, no relu needed\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x142 and 1x1)"
     ]
    }
   ],
   "source": [
    "preds =[]\n",
    "all_y = []\n",
    "# save all predictions\n",
    "for batch in dataloader_val:\n",
    "    # adjust this to work with your model\n",
    "    x,y = batch\n",
    "    x = torch.unsqueeze(x,1)\n",
    "    y_hat = cnn_model(x.cuda())\n",
    "    preds.append(y_hat.squeeze().detach().numpy())\n",
    "    all_y.append(y.detach().numpy())\n",
    "\n",
    "# concatenate and plot\n",
    "preds= np.concatenate(preds)\n",
    "all_y = np.concatenate(all_y)\n",
    "\n",
    "sns.regplot(x=preds,y=all_y)\n",
    "plt.xlabel(\"Predicted ddG\")\n",
    "plt.ylabel(\"Measured ddG\")\n",
    "\n",
    "# get RMSE, Pearson and Spearman correlation \n",
    "print(\"RMSE:\", skmetrics.mean_squared_error(all_y, preds, squared=False))\n",
    "print(\"Pearson r:\", scipy.stats.pearsonr(preds, all_y))\n",
    "print(\"Spearman r:\", scipy.stats.spearmanr(preds, all_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1467475), started 1:39:32 ago. (Use '!kill 1467475' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8675b47bad11ea86\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8675b47bad11ea86\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fa888489dcef296c36d3d3b759d2bbafdf14549bdfa862d5619a4427d05b08f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
